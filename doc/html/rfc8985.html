<!DOCTYPE html> 

<!-- template: /a/www/ietf-datatracker/web/ietf/templates/doc/htmlized_base.html -->
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>
  
    rfc8985
  
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

  @media only screen 
    and (min-width: 992px)
    and (max-width: 1199px) {
      body { font-size: 14pt; }
            div.content { width: 96ex; margin: 0 auto; }
        }
  @media only screen 
    and (min-width: 768px)
    and (max-width: 991px) {
            body { font-size: 14pt; }
            div.content { width: 96ex; margin: 0 auto; }
        }
  @media only screen 
    and (min-width: 480px)
    and (max-width: 767px) {
            body { font-size: 11pt; }
            div.content { width: 96ex; margin: 0 auto; }
        }
  @media only screen 
    and (max-width: 479px) {
            body { font-size: 8pt; }
            div.content { width: 96ex; margin: 0 auto; }
        }
  @media only screen 
    and (min-device-width : 375px) 
    and (max-device-width : 667px) {
            body { font-size: 9.5pt; }
            div.content { width: 96ex; margin: 0; }
        }
  @media only screen 
    and (min-device-width: 1200px) {
            body { font-size: 10pt; margin: 0 4em; }
            div.content { width: 96ex; margin: 0; }
        }
        h1, h2, h3, h4, h5, h6, .h1, .h2, .h3, .h4, .h5, .h6 {
      font-weight: bold;
            /* line-height: 0pt; */
            display: inline;
            white-space: pre;
            font-family: monospace;
            font-size: 1em;
      font-weight: bold;
        }
        pre {
            font-size: 1em;
            margin-top: 0px;
            margin-bottom: 0px;
        }
  .pre {
      white-space: pre;
      font-family: monospace;
  }
  .header{
      font-weight: bold;
  }
        .newpage {
            page-break-before: always;
        }
        .invisible {
            text-decoration: none;
            color: white;
        }
        @media print {
            body {
                margin-top: 5em;
                font-family: monospace;
                font-size: 10.5pt;
            }
            h1, h2, h3, h4, h5, h6 {
                font-size: 1em;
            }
        
            a:link, a:visited {
                color: inherit;
                text-decoration: none;
            }
            .noprint {
                display: none;
            }
        }
  @media screen {
      .grey, .grey a:link, .grey a:visited {
    color: #777;
      }
            .meta-info {
                background-color: #EEE;
            }
            .top {
                border-top: 7px solid #EEE;
            }
            .pad {
                padding-top: 7px;
                line-height: 24px;
                padding-bottom: 4px;
            }
            .bgwhite  { background-color: white; }
            .bgred    { background-color: #F44; }
            .bggrey   { background-color: #666; }
            .bgbrown  { background-color: #840; }            
            .bgorange { background-color: #FA0; }
            .bgyellow { background-color: #EE0; }
            .bgmagenta{ background-color: #F4F; }
            .bgblue   { background-color: #66F; }
            .bgcyan   { background-color: #4DD; }
            .bggreen  { background-color: #4F4; }

            .legend   { font-size: 90%; }
            .cplate   { font-size: 70%; border: solid grey 1px; }
  }
    
     

.bgwhite  { background-color: white; }
.bgred    { background-color: #F44; }
.bggrey   { background-color: #666; }
.bgbrown  { background-color: #840; }            
.bgorange { background-color: #FA0; }
.bgyellow { background-color: #EE0; }
.bgmagenta{ background-color: #F4F; }
.bgblue   { background-color: #66F; }
.bgcyan   { background-color: #4DD; }
.bggreen  { background-color: #4F4; }

.draftcontent { margin-top:0px !important;}


    </style>

    <!--[if lt IE 9]>
        <script src="https://www.ietf.org/lib/dt/7.33.0/html5shiv/html5shiv.min.js"></script>
        <script src="https://www.ietf.org/lib/dt/7.33.0/respond/dest/respond.min.js"></script>
    <![endif]-->
    
  <link rel="alternate" type="application/atom+xml" title="Document changes" href="/feed/document-changes/draft-ietf-tcpm-rack/">
  <meta name="description" content="The RACK-TLP Loss Detection Algorithm for TCP (RFC )">
  <script src="https://www.ietf.org/lib/dt/7.33.0/d3/d3.min.js"></script>
  <script src="https://www.ietf.org/lib/dt/7.33.0/jquery/jquery.min.js"></script>


    
    <link rel="shortcut icon" href="https://www.ietf.org/lib/dt/7.33.0/ietf/images/ietf-icon-blue3.png">
    
    <link rel="apple-touch-icon" href="https://www.ietf.org/lib/dt/7.33.0/ietf/images/apple-touch-icon.png">
  </head>

  <body style="padding-top: 0;">

	  <div class="content" id="content">
        
  <!-- template: /a/www/ietf-datatracker/web/ietf/templates/doc/document_html.html -->
 
  <div class="rfcmarkup">
    <div class="noprint" style="height: 6px;">
      <div onmouseover="this.style.cursor='pointer';"
         onclick="showLegend();"
         onmouseout="hideLegend()"
         style="height: 6px; min-height: 6px; width: 96ex; position: absolute; margin-top:0; "
         class="meta-info bgblue"
         title="Click for colour legend." >&nbsp;</div>
      <div id="legend"
           class="meta-info noprint pre legend"
           style="position:absolute; top: 4px; left: 4ex; visibility:hidden; background-color: white; padding: 4px 9px 5px 7px; border: solid #345 1px; "
           onmouseover="showLegend();"
           onmouseout="hideLegend();">
      </div>
    </div>

    
      <div class="noprint">
	 <pre class="pre meta-info">[<a href="https://datatracker.ietf.org" title="Document search and retrieval page">Search</a>] [<a href="https://www.rfc-editor.org/rfc/rfc8985.txt" title="Plaintext version of this document">txt</a>|<a href="https://www.rfc-editor.org/rfc/rfc8985.html" title="HTML version of this document, from XML2RFC">html</a>|<a href="https://www.rfc-editor.org/rfc/rfc8985.xml" title="XML source for this document">xml</a>|<a href="https://www.rfc-editor.org/rfc/rfc8985.pdf" title="PDF version of this document">pdf</a>|<a href="/doc/rfc8985/bibtex" title="BibTex entry for this document">bibtex</a>] [<a href="/doc/rfc8985/" title="Datatracker information for this document">Tracker</a>] [<a href="/group/tcpm/" title="The working group handling this document">WG</a>] [<a href="mailto:draft-ietf-tcpm-rack@ietf.org?subject=draft-ietf-tcpm-rack" title="Send email to the document authors">Email</a>] [<a href="https://www.ietf.org/rfcdiff?difftype=--hwdiff&url2=draft-ietf-tcpm-rack-15.txt" title="Inline diff (wdiff)">Diff1</a>] [<a href="https://www.ietf.org/rfcdiff?url2=draft-ietf-tcpm-rack-15.txt" title="Side-by-side diff">Diff2</a>] [<a href="https://www.ietf.org/tools/idnits?url=https://www.ietf.org/archive/id/draft-ietf-tcpm-rack-15.txt" title="Run an idnits check of this document">Nits</a>]

From: <a href="/doc/html/draft-ietf-tcpm-rack-15">draft-ietf-tcpm-rack-15</a>                          Proposed Standard</pre>
      </div>
    

    <div class="draftcontent">
    <pre>Internet Engineering Task Force (IETF)                          Y. Cheng
Request for Comments: 8985                                   N. Cardwell
Category: Standards Track                                   N. Dukkipati
ISSN: 2070-1721                                                   P. Jha
                                                            Google, Inc.
                                                           February 2021


             <span class="h1">The RACK-TLP Loss Detection Algorithm for TCP</span>

Abstract

   This document presents the RACK-TLP loss detection algorithm for TCP.
   RACK-TLP uses per-segment transmit timestamps and selective
   acknowledgments (SACKs) and has two parts.  Recent Acknowledgment
   (RACK) starts fast recovery quickly using time-based inferences
   derived from acknowledgment (ACK) feedback, and Tail Loss Probe (TLP)
   leverages RACK and sends a probe packet to trigger ACK feedback to
   avoid retransmission timeout (RTO) events.  Compared to the widely
   used duplicate acknowledgment (DupAck) threshold approach, RACK-TLP
   detects losses more efficiently when there are application-limited
   flights of data, lost retransmissions, or data packet reordering
   events.  It is intended to be an alternative to the DupAck threshold
   approach.

Status of This Memo

   This is an Internet Standards Track document.

   This document is a product of the Internet Engineering Task Force
   (IETF).  It represents the consensus of the IETF community.  It has
   received public review and has been approved for publication by the
   Internet Engineering Steering Group (IESG).  Further information on
   Internet Standards is available in <a href="/doc/html/rfc7841#section-2">Section&nbsp;2 of RFC 7841</a>.

   Information about the current status of this document, any errata,
   and how to provide feedback on it may be obtained at
   <a href="https://www.rfc-editor.org/info/rfc8985">https://www.rfc-editor.org/info/rfc8985</a>.

Copyright Notice

   Copyright (c) 2021 IETF Trust and the persons identified as the
   document authors.  All rights reserved.

   This document is subject to <a href="/doc/html/bcp78">BCP 78</a> and the IETF Trust&#x27;s Legal
   Provisions Relating to IETF Documents
   (<a href="https://trustee.ietf.org/license-info">https://trustee.ietf.org/license-info</a>) in effect on the date of
   publication of this document.  Please review these documents
   carefully, as they describe your rights and restrictions with respect
   to this document.  Code Components extracted from this document must
   include Simplified BSD License text as described in Section 4.e of
   the Trust Legal Provisions and are provided without warranty as
   described in the Simplified BSD License.

Table of Contents

   1.  Introduction
     1.1.  Background
     1.2.  Motivation
   2.  Terminology
   3.  RACK-TLP High-Level Design
     3.1.  RACK: Time-Based Loss Inferences from ACKs
     3.2.  TLP: Sending One Segment to Probe Losses Quickly with RACK
     3.3.  RACK-TLP: Reordering Resilience with a Time Threshold
       3.3.1.  Reordering Design Rationale
       3.3.2.  Reordering Window Adaptation
     3.4.  An Example of RACK-TLP in Action: Fast Recovery
     3.5.  An Example of RACK-TLP in Action: RTO
     3.6.  Design Summary
   4.  Requirements
   5.  Definitions
     5.1.  Terms
     5.2.  Per-Segment Variables
     5.3.  Per-Connection Variables
     5.4.  Per-Connection Timers
   6.  RACK Algorithm Details
     6.1.  Upon Transmitting a Data Segment
     6.2.  Upon Receiving an ACK
     6.3.  Upon RTO Expiration
   7.  TLP Algorithm Details
     7.1.  Initializing State
     7.2.  Scheduling a Loss Probe
     7.3.  Sending a Loss Probe upon PTO Expiration
     7.4.  Detecting Losses Using the ACK of the Loss Probe
       7.4.1.  General Case: Detecting Packet Losses Using RACK
       7.4.2.  Special Case: Detecting a Single Loss Repaired by the
               Loss Probe
   8.  Managing RACK-TLP Timers
   9.  Discussion
     9.1.  Advantages and Disadvantages
     9.2.  Relationships with Other Loss Recovery Algorithms
     9.3.  Interaction with Congestion Control
     9.4.  TLP Recovery Detection with Delayed ACKs
     9.5.  RACK-TLP for Other Transport Protocols
   10. Security Considerations
   11. IANA Considerations
   12. References
     12.1.  Normative References
     12.2.  Informative References
   Acknowledgments
   Authors&#x27; Addresses

<span class="h2"><a class="selflink" id="section-1" href="#section-1">1</a>.  Introduction</span>

   This document presents RACK-TLP, a TCP loss detection algorithm that
   improves upon the widely implemented duplicate acknowledgment
   (DupAck) counting approach described in [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] and [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>]; it
   is RECOMMENDED as an alternative to that earlier approach.  RACK-TLP
   has two parts.  Recent Acknowledgment (RACK) detects losses quickly
   using time-based inferences derived from ACK feedback.  Tail Loss
   Probe (TLP) triggers ACK feedback by quickly sending a probe segment
   to avoid retransmission timeout (RTO) events.

<span class="h3"><a class="selflink" id="section-1.1" href="#section-1.1">1.1</a>.  Background</span>

   In traditional TCP loss recovery algorithms [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>], a
   sender starts fast recovery when the number of DupAcks received
   reaches a threshold (DupThresh) that defaults to 3 (this approach is
   referred to as &quot;DupAck counting&quot; in the rest of the document).  The
   sender also halves the congestion window during the recovery.  The
   rationale behind the partial window reduction is that congestion does
   not seem severe since ACK clocking is still maintained.  The time
   elapsed in fast recovery can be just one round trip, e.g., if the
   sender uses SACK-based recovery [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>] and the number of lost
   segments is small.

   If fast recovery is not triggered or is triggered but fails to repair
   all the losses, then the sender resorts to RTO recovery.  The RTO
   timer interval is conservatively the smoothed RTT (SRTT) plus four
   times the RTT variation, and is lower bounded to 1 second [<a href="/doc/html/rfc6298" title="&quot;Computing TCP&#x27;s Retransmission Timer&quot;">RFC6298</a>].
   Upon RTO timer expiration, the sender retransmits the first
   unacknowledged segment and resets the congestion window to the loss
   window value (by default, 1 full-sized segment [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>]).  The
   rationale behind the congestion window reset is that an entire flight
   of data and the ACK clock were lost, so this deserves a cautious
   response.  The sender then retransmits the rest of the data following
   the slow start algorithm [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>].  The time elapsed in RTO recovery
   is one RTO interval plus the number of round trips needed to repair
   all the losses.

<span class="h3"><a class="selflink" id="section-1.2" href="#section-1.2">1.2</a>.  Motivation</span>

   Fast recovery is the preferred form of loss recovery because it can
   potentially recover all losses in the timescale of a single round
   trip, with only a fractional congestion window reduction.  RTO
   recovery and congestion window reset should ideally be the last
   resort and should ideally be used only when the entire flight is
   lost.  However, in addition to losing an entire flight of data, the
   following situations can unnecessarily resort to RTO recovery with
   traditional TCP loss recovery algorithms [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>]:

   1.  Packet drops for short flows or at the end of an application data
       flight.  When the sender is limited by the application (e.g.,
       structured request/response traffic), segments lost at the end of
       the application data transfer often can only be recovered by RTO.
       Consider an example where only the last segment in a flight of
       100 segments is lost.  Lacking any DupAck, the sender RTO
       expires, reduces the congestion window to 1, and raises the
       congestion window to just 2 after the loss repair is
       acknowledged.  In contrast, any single segment loss occurring
       between the first and the 97th segment would result in fast
       recovery, which would only cut the window in half.

   2.  Lost retransmissions.  Heavy congestion or traffic policers can
       cause retransmissions to be lost.  Lost retransmissions cause a
       resort to RTO recovery since DupAck counting does not detect the
       loss of the retransmissions.  Then the slow start after RTO
       recovery could cause burst losses again, which severely degrades
       performance [<a href="#ref-POLICER16">POLICER16</a>].

   3.  Packet reordering.  In this document, &quot;reordering&quot; refers to the
       events where segments are delivered at the TCP receiver in a
       chronological order different from their chronological
       transmission order.  Link-layer protocols (e.g., 802.11 block
       ACK), link bonding, or routers&#x27; internal load balancing (e.g.,
       ECMP) can deliver TCP segments out of order.  The degree of such
       reordering is usually within the order of the path round-trip
       time.  If the reordering degree is beyond DupThresh, DupAck
       counting can cause a spurious fast recovery and unnecessary
       congestion window reduction.  To mitigate the issue, Non-
       Congestion Robustness (NCR) for TCP [<a href="/doc/html/rfc4653" title="&quot;Improving the Robustness of TCP to Non- Congestion Events&quot;">RFC4653</a>] increases the
       DupThresh from the current fixed value of three duplicate ACKs
       [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] to approximate a congestion window of data having left
       the network.

<span class="h2"><a class="selflink" id="section-2" href="#section-2">2</a>.  Terminology</span>

   The key words &quot;MUST&quot;, &quot;MUST NOT&quot;, &quot;REQUIRED&quot;, &quot;SHALL&quot;, &quot;SHALL NOT&quot;,
   &quot;SHOULD&quot;, &quot;SHOULD NOT&quot;, &quot;RECOMMENDED&quot;, &quot;NOT RECOMMENDED&quot;, &quot;MAY&quot;, and
   &quot;OPTIONAL&quot; in this document are to be interpreted as described in
   <a href="/doc/html/bcp14">BCP 14</a> [<a href="/doc/html/rfc2119" title="&quot;Key words for use in RFCs to Indicate Requirement Levels&quot;">RFC2119</a>] [<a href="/doc/html/rfc8174" title="&quot;Ambiguity of Uppercase vs Lowercase in RFC 2119 Key Words&quot;">RFC8174</a>] when, and only when, they appear in all
   capitals, as shown here.

<span class="h2"><a class="selflink" id="section-3" href="#section-3">3</a>.  RACK-TLP High-Level Design</span>

   RACK-TLP allows senders to recover losses more effectively in all
   three scenarios described in the previous section.  There are two
   design principles behind RACK-TLP.  The first principle is to detect
   losses via ACK events as much as possible, to repair losses at round-
   trip timescales.  The second principle is to gently probe the network
   to solicit additional ACK feedback, to avoid RTO expiration and
   subsequent congestion window reset.  At a high level, the two
   principles are implemented in RACK and TLP, respectively.

<span class="h3"><a class="selflink" id="section-3.1" href="#section-3.1">3.1</a>.  RACK: Time-Based Loss Inferences from ACKs</span>

   The rationale behind RACK is that if a segment is delivered out of
   order, then the segments sent chronologically before that were either
   lost or reordered.  This concept is not fundamentally different from
   those described in [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>], [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>], or [<a href="#ref-FACK" title="&quot;Forward acknowledgement: refining TCP congestion control&quot;">FACK</a>].  RACK&#x27;s key
   innovation is using per-segment transmission timestamps and widely
   deployed SACK [<a href="/doc/html/rfc2018" title="&quot;TCP Selective Acknowledgment Options&quot;">RFC2018</a>] options to conduct time-based inferences
   instead of inferring losses by counting ACKs or SACKed sequences.
   Time-based inferences are more robust than DupAck counting approaches
   because they do not depend on flight size and thus are effective for
   application-limited traffic.

   Conceptually, RACK keeps a virtual timer for every data segment sent
   (including retransmissions).  Each timer expires dynamically based on
   the latest RTT measurements plus an additional delay budget to
   accommodate potential packet reordering (called the &quot;reordering
   window&quot;).  When a segment&#x27;s timer expires, RACK marks the
   corresponding segment as lost for retransmission.

   In reality, as an algorithm, RACK does not arm a timer for every
   segment sent because it&#x27;s not necessary.  Instead, the sender records
   the most recent transmission time of every data segment sent,
   including retransmissions.  For each ACK received, the sender
   calculates the latest RTT measurement (if eligible) and adjusts the
   expiration time of every segment sent but not yet delivered.  If a
   segment has expired, RACK marks it as lost.

   Since the time-based logic of RACK applies equally to retransmissions
   and original transmissions, it can detect lost retransmissions as
   well.  If a segment has been retransmitted but its most recent
   (re)transmission timestamp has expired, then, after a reordering
   window, it&#x27;s marked as lost.

<span class="h3"><a class="selflink" id="section-3.2" href="#section-3.2">3.2</a>.  TLP: Sending One Segment to Probe Losses Quickly with RACK</span>

   RACK infers losses from ACK feedback; however, in some cases, ACKs
   are sparse, particularly when the inflight is small or when the
   losses are high.  In some challenging cases, the last few segments in
   a flight are lost.  With the operations described in [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] or
   [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>], the sender&#x27;s RTO would expire and reset the congestion
   window when, in reality, most of the flight has been delivered.

   Consider an example where a sender with a large congestion window
   transmits 100 new data segments after an application write and only
   the last three segments are lost.  Without RACK-TLP, the RTO expires,
   the sender retransmits the first unacknowledged segment, and the
   congestion window slow starts from 1.  After all the retransmits are
   acknowledged, the congestion window is increased to 4.  The total
   delivery time for this application transfer is three RTTs plus one
   RTO, a steep cost given that only a tiny fraction of the flight was
   lost.  If instead the losses had occurred three segments sooner in
   the flight, then fast recovery would have recovered all losses within
   one round trip and would have avoided resetting the congestion
   window.

   Fast recovery would be preferable in such scenarios; TLP is designed
   to trigger the feedback RACK needed to enable that.  After the last
   (100th) segment was originally sent, TLP sends the next available
   (new) segment or retransmits the last (highest-sequenced) segment in
   two round trips to probe the network, hence the name &quot;Tail Loss
   Probe&quot;.  The successful delivery of the probe would solicit an ACK.
   RACK uses this ACK to detect that the 98th and 99th segments were
   lost, trigger fast recovery, and retransmit both successfully.  The
   total recovery time is four RTTs, and the congestion window is only
   partially reduced instead of being fully reset.  If the probe was
   also lost, then the sender would invoke RTO recovery, resetting the
   congestion window.

<span class="h3"><a class="selflink" id="section-3.3" href="#section-3.3">3.3</a>.  RACK-TLP: Reordering Resilience with a Time Threshold</span>

<span class="h4"><a class="selflink" id="section-3.3.1" href="#section-3.3.1">3.3.1</a>.  Reordering Design Rationale</span>

   Upon receiving an ACK indicating a SACKed segment, a sender cannot
   tell immediately whether that was a result of reordering or loss.  It
   can only distinguish between the two in hindsight if the missing
   sequence ranges are filled in later without retransmission.  Thus, a
   loss detection algorithm needs to budget some wait time -- a
   reordering window -- to try to disambiguate packet reordering from
   packet loss.

   The reordering window in the DupAck counting approach is implicitly
   defined as the elapsed time to receive DupThresh SACKed segments or
   duplicate acknowledgments.  This approach is effective if the network
   reordering degree (in sequence distance) is smaller than DupThresh
   and at least DupThresh segments after the loss is acknowledged.  For
   cases where the reordering degree is larger than the default
   DupThresh of 3 packets, one alternative is to dynamically adapt
   DupThresh based on the FlightSize (e.g., the sender adjusts the
   DupThresh to half of the FlightSize).  However, this does not work
   well with the following two types of reordering:

   1.  Application-limited flights where the last non-full-sized segment
       is delivered first and then the remaining full-sized segments in
       the flight are delivered in order.  This reordering pattern can
       occur when segments traverse parallel forwarding paths.  In such
       scenarios, the degree of reordering in packet distance is one
       segment less than the flight size.

   2.  A flight of segments that are delivered partially out of order.
       One cause for this pattern is wireless link-layer retransmissions
       with an inadequate reordering buffer at the receiver.  In such
       scenarios, the wireless sender sends the data packets in order
       initially, but some are lost and then recovered by link-layer
       retransmissions; the wireless receiver delivers the TCP data
       packets in the order they are received due to the inadequate
       reordering buffer.  The random wireless transmission errors in
       such scenarios cause the reordering degree, expressed in packet
       distance, to have highly variable values up to the flight size.

   In the above two cases, the degree of reordering in packet distance
   is highly variable.  This makes the DupAck counting approach
   ineffective, including dynamic adaptation variants as in [<a href="/doc/html/rfc4653" title="&quot;Improving the Robustness of TCP to Non- Congestion Events&quot;">RFC4653</a>].
   Instead, the degree of reordering in time difference in such cases is
   usually within a single round-trip time.  This is because the packets
   either traverse disjoint paths with similar propagation delays or are
   repaired quickly by the local access technology.  Hence, using a time
   threshold instead of a packet threshold strikes a middle ground,
   allowing a bounded degree of reordering resilience while still
   allowing fast recovery.  This is the rationale behind the RACK-TLP
   reordering resilience design.

   Specifically, RACK-TLP introduces a new dynamic reordering window
   parameter in time units, and the sender considers a data segment S
   lost if both of these conditions are met:

   1.  Another data segment sent later than S has been delivered.

   2.  S has not been delivered after the estimated round-trip time plus
       the reordering window.

   Note that condition (1) implies at least one round trip of time has
   elapsed since S has been sent.

<span class="h4"><a class="selflink" id="section-3.3.2" href="#section-3.3.2">3.3.2</a>.  Reordering Window Adaptation</span>

   The RACK reordering window adapts to the measured duration of
   reordering events within reasonable and specific bounds to
   disincentivize excessive reordering.  More specifically, the sender
   sets the reordering window as follows:

   1.  The reordering window SHOULD be set to zero if no reordering has
       been observed on the connection so far, and either (a) three
       segments have been SACKed since the last recovery or (b) the
       sender is already in fast or RTO recovery.  Otherwise, the
       reordering window SHOULD start from a small fraction of the
       round-trip time or zero if no round-trip time estimate is
       available.

   2.  The RACK reordering window SHOULD adaptively increase (using the
       algorithm in &quot;Step 4: Update RACK reordering window&quot; below) if
       the sender receives a Duplicate Selective Acknowledgment (DSACK)
       option [<a href="/doc/html/rfc2883" title="&quot;An Extension to the Selective Acknowledgement (SACK) Option for TCP&quot;">RFC2883</a>].  Receiving a DSACK suggests the sender made a
       spurious retransmission, which may have been due to the
       reordering window being too small.

   3.  The RACK reordering window MUST be bounded, and this bound SHOULD
       be SRTT.

   Rules 2 and 3 are required to adapt to reordering caused by dynamics
   such as the prolonged link-layer loss recovery episodes described
   earlier.  Each increase in the reordering window requires a new round
   trip where the sender receives a DSACK; thus, depending on the extent
   of reordering, it may take multiple round trips to fully adapt.

   For short flows, the low initial reordering window helps recover
   losses quickly, at the risk of spurious retransmissions.  The
   rationale is that spurious retransmissions for short flows are not
   expected to produce excessive additional network traffic.  For long
   flows, the design tolerates reordering within a round trip.  This
   handles reordering in small timescales (reordering within the round-
   trip time of the shortest path).

   However, the fact that the initial reordering window is low and the
   reordering window&#x27;s adaptive growth is bounded means that there will
   continue to be a cost to reordering that disincentivizes excessive
   reordering.

<span class="h3"><a class="selflink" id="section-3.4" href="#section-3.4">3.4</a>.  An Example of RACK-TLP in Action: Fast Recovery</span>

   The following example in Figure 1 illustrates the RACK-TLP algorithm
   in action:

    Event  TCP DATA SENDER                            TCP DATA RECEIVER
    _____  ____________________________________________________________
      1.   Send P0, P1, P2, P3          --&gt;
           [P1, P2, P3 dropped by network]

      2.                                &lt;--          Receive P0, ACK P0

      3a.  2RTTs after (2), TLP timer fires
      3b.  TLP: retransmits P3          --&gt;

      4.                                &lt;--         Receive P3, SACK P3

      5a.  Receive SACK for P3
      5b.  RACK: marks P1, P2 lost
      5c.  Retransmit P1, P2            --&gt;
           [P1 retransmission dropped by network]

      6.                                &lt;--    Receive P2, SACK P2 &amp; P3

      7a.  RACK: marks P1 retransmission lost
      7b.  Retransmit P1                --&gt;

      8.                                &lt;--          Receive P1, ACK P3

                    Figure 1: RACK-TLP Protocol Example

   Figure 1 illustrates a sender sending four segments (P0, P1, P2, P3)
   and losing the last three segments.  After two round trips, TLP sends
   a loss probe, retransmitting the last segment, P3, to solicit SACK
   feedback and restore the ACK clock (Event 3).  The delivery of P3
   enables RACK to infer (Event 5b) that P1 and P2 were likely lost
   because they were sent before P3.  The sender then retransmits P1 and
   P2.  Unfortunately, the retransmission of P1 is lost again.  However,
   the delivery of the retransmission of P2 allows RACK to infer that
   the retransmission of P1 was likely lost (Event 7a); hence, P1 should
   be retransmitted (Event 7b).  Note that [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] mandates a
   principle that loss in two successive windows of data or the loss of
   a retransmission must be taken as two indications of congestion and
   therefore results in two separate congestion control reactions.

<span class="h3"><a class="selflink" id="section-3.5" href="#section-3.5">3.5</a>.  An Example of RACK-TLP in Action: RTO</span>

   In addition to enhancing fast recovery, RACK improves the accuracy of
   RTO recovery by reducing spurious retransmissions.

   Without RACK, upon RTO timer expiration, the sender marks all the
   unacknowledged segments as lost.  This approach can lead to spurious
   retransmissions.  For example, consider a simple case where one
   segment was sent with an RTO of 1 second and then the application
   writes more data, causing a second and third segment to be sent right
   before the RTO of the first segment expires.  Suppose none of the
   segments were lost.  Without RACK, if there is a spurious RTO, then
   the sender marks all three segments as lost and retransmits the first
   segment.  If the ACK for the original copy of the first segment
   arrives right after the spurious RTO retransmission, then the sender
   continues slow start and spuriously retransmits the second and third
   segments since it (erroneously) presumed they are lost.

   With RACK, upon RTO timer expiration, the only segment automatically
   marked as lost is the first segment (since it was sent an RTO ago);
   for all the other segments, RACK only marks the segment as lost if at
   least one round trip has elapsed since the segment was transmitted.
   Consider the previous example scenario, but this time with RACK.
   With RACK, when the RTO expires, the sender only marks the first
   segment as lost and retransmits that segment.  The other two very
   recently sent segments are not marked as lost because they were sent
   less than one round trip ago and there were no ACKs providing
   evidence that they were lost.  Upon receiving the ACK for the RTO
   retransmission, the RACK sender would not yet retransmit the second
   or third segment, but rather would re-arm the RTO timer and wait for
   a new RTO interval to elapse before marking the second or third
   segment as lost.

<span class="h3"><a class="selflink" id="section-3.6" href="#section-3.6">3.6</a>.  Design Summary</span>

   To summarize, RACK-TLP aims to adapt to small time-varying degrees of
   reordering, quickly recover most losses within one to two round
   trips, and avoid costly RTO recoveries.  In the presence of
   reordering, the adaptation algorithm can impose sometimes needless
   delays when it waits to disambiguate loss from reordering, but the
   penalty for waiting is bounded to one round trip, and such delays are
   confined to flows long enough to have observed reordering.

<span class="h2"><a class="selflink" id="section-4" href="#section-4">4</a>.  Requirements</span>

   The reader is expected to be familiar with the definitions given in
   the TCP congestion control [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>], selective acknowledgment
   [<a href="/doc/html/rfc2018" title="&quot;TCP Selective Acknowledgment Options&quot;">RFC2018</a>], and loss recovery [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>] RFCs.  RACK-TLP has the
   following requirements:

   1.  The connection MUST use selective acknowledgment (SACK) options
       [<a href="/doc/html/rfc2018" title="&quot;TCP Selective Acknowledgment Options&quot;">RFC2018</a>], and the sender MUST keep SACK scoreboard information
       on a per-connection basis (&quot;SACK scoreboard&quot; has the same meaning
       here as in <a href="/doc/html/rfc6675#section-3">[RFC6675], Section&nbsp;3</a>).

   2.  For each data segment sent, the sender MUST store its most recent
       transmission time with a timestamp whose granularity is finer
       than 1/4 of the minimum RTT of the connection.  At the time of
       writing, microsecond resolution is suitable for intra-data center
       traffic, and millisecond granularity or finer is suitable for the
       Internet.  Note that RACK-TLP can be implemented with TSO (TCP
       Segmentation Offload) support by having multiple segments in a
       TSO aggregate share the same timestamp.

   3.  RACK DSACK-based reordering window adaptation is RECOMMENDED but
       is not required.

   4.  TLP requires RACK.

<span class="h2"><a class="selflink" id="section-5" href="#section-5">5</a>.  Definitions</span>

   The reader is expected to be familiar with the variables SND.UNA,
   SND.NXT, SEG.ACK, and SEG.SEQ in [<a href="/doc/html/rfc793" title="&quot;Transmission Control Protocol&quot;">RFC793</a>]; Sender Maximum Segment
   Size (SMSS) and FlightSize in [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>]; DupThresh in [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>]; and
   RTO and SRTT in [<a href="/doc/html/rfc6298" title="&quot;Computing TCP&#x27;s Retransmission Timer&quot;">RFC6298</a>].  A RACK-TLP implementation uses several
   new terms and needs to store new per-segment and per-connection
   state, described below.

<span class="h3"><a class="selflink" id="section-5.1" href="#section-5.1">5.1</a>.  Terms</span>

   These terms are used to explain the variables and algorithms below:

   RACK.segment
      Among all the segments that have been either selectively or
      cumulatively acknowledged, the term &quot;RACK.segment&quot; denotes the
      segment that was sent most recently (including retransmissions).

   RACK.ack_ts
      Denotes the time when the full sequence range of RACK.segment was
      selectively or cumulatively acknowledged.

<span class="h3"><a class="selflink" id="section-5.2" href="#section-5.2">5.2</a>.  Per-Segment Variables</span>

   These variables indicate the status of the most recent transmission
   of a data segment:

   Segment.lost
      True if the most recent (re)transmission of the segment has been
      marked as lost and needs to be retransmitted.  False otherwise.

   Segment.retransmitted
      True if the segment has ever been retransmitted.  False otherwise.

   Segment.xmit_ts
      The time of the last transmission of a data segment, including
      retransmissions, if any, with a clock granularity specified in the
      &quot;Requirements&quot; section.  A maximum value INFINITE_TS indicates an
      invalid timestamp that represents that the segment is not
      currently in flight.

   Segment.end_seq
      The next sequence number after the last sequence number of the
      data segment.

<span class="h3"><a class="selflink" id="section-5.3" href="#section-5.3">5.3</a>.  Per-Connection Variables</span>

   RACK.xmit_ts
      The latest transmission timestamp of RACK.segment.

   RACK.end_seq
      The Segment.end_seq of RACK.segment.

   RACK.segs_sacked
      Returns the total number of segments selectively acknowledged in
      the SACK scoreboard.

   RACK.fack
      The highest selectively or cumulatively acknowledged sequence
      (i.e., forward acknowledgment).

   RACK.min_RTT
      The estimated minimum round-trip time (RTT) of the connection.

   RACK.rtt
      The RTT of the most recently delivered segment on the connection
      (either cumulatively acknowledged or selectively acknowledged)
      that was not marked as invalid as a possible spurious
      retransmission.

   RACK.reordering_seen
      Indicates whether the sender has detected data segment reordering
      event(s).

   RACK.reo_wnd
      A reordering window computed in the unit of time used for
      recording segment transmission times.  It is used to defer the
      moment at which RACK marks a segment as lost.

   RACK.dsack_round
      Indicates if a DSACK option has been received in the latest round
      trip.

   RACK.reo_wnd_mult
      The multiplier applied to adjust RACK.reo_wnd.

   RACK.reo_wnd_persist
      The number of loss recoveries before resetting RACK.reo_wnd.

   TLP.is_retrans
      A boolean indicating whether there is an unacknowledged TLP
      retransmission.

   TLP.end_seq
      The value of SND.NXT at the time of sending a TLP probe.

   TLP.max_ack_delay:
      The sender&#x27;s budget for the maximum delayed ACK interval.

<span class="h3"><a class="selflink" id="section-5.4" href="#section-5.4">5.4</a>.  Per-Connection Timers</span>

   RACK reordering timer
      A timer that allows RACK to wait for reordering to resolve in
      order to try to disambiguate reordering from loss when some
      segments are marked as SACKed.

   TLP PTO
      A timer event indicating that an ACK is overdue and the sender
      should transmit a TLP segment to solicit SACK or ACK feedback.

   These timers augment the existing timers maintained by a sender,
   including the RTO timer [<a href="/doc/html/rfc6298" title="&quot;Computing TCP&#x27;s Retransmission Timer&quot;">RFC6298</a>].  A RACK-TLP sender arms one of
   these three timers -- RACK reordering timer, TLP PTO timer, or RTO
   timer -- when it has unacknowledged segments in flight.  The
   implementation can simplify managing all three timers by multiplexing
   a single timer among them with an additional variable to indicate the
   event to invoke upon the next timer expiration.

<span class="h2"><a class="selflink" id="section-6" href="#section-6">6</a>.  RACK Algorithm Details</span>

<span class="h3"><a class="selflink" id="section-6.1" href="#section-6.1">6.1</a>.  Upon Transmitting a Data Segment</span>

   Upon transmitting a new segment or retransmitting an old segment,
   record the time in Segment.xmit_ts and set Segment.lost to FALSE.
   Upon retransmitting a segment, set Segment.retransmitted to TRUE.

   RACK_transmit_new_data(Segment):
           Segment.xmit_ts = Now()
           Segment.lost = FALSE

   RACK_retransmit_data(Segment):
           Segment.retransmitted = TRUE
           Segment.xmit_ts = Now()
           Segment.lost = FALSE

<span class="h3"><a class="selflink" id="section-6.2" href="#section-6.2">6.2</a>.  Upon Receiving an ACK</span>

   Step 1: Update RACK.min_RTT.

   Use the RTT measurements obtained via [<a href="/doc/html/rfc6298" title="&quot;Computing TCP&#x27;s Retransmission Timer&quot;">RFC6298</a>] or [<a href="/doc/html/rfc7323" title="&quot;TCP Extensions for High Performance&quot;">RFC7323</a>] to
   update the estimated minimum RTT in RACK.min_RTT.  The sender SHOULD
   track a windowed min-filtered estimate of recent RTT measurements
   that can adapt when migrating to significantly longer paths rather
   than tracking a simple global minimum of all RTT measurements.

   Step 2: Update the state for the most recently sent segment that has
   been delivered.

   In this step, RACK updates the state that tracks the most recently
   sent segment that has been delivered: RACK.segment.  RACK maintains
   its latest transmission timestamp in RACK.xmit_ts and its highest
   sequence number in RACK.end_seq.  These two variables are used in
   later steps to estimate if some segments not yet delivered were
   likely lost.  Given the information provided in an ACK, each segment
   cumulatively ACKed or SACKed is marked as delivered in the
   scoreboard.  Because an ACK can also acknowledge retransmitted data
   segments and because retransmissions can be spurious, the sender
   needs to take care to avoid spurious inferences.  For example, if the
   sender were to use timing information from a spurious retransmission,
   the RACK.rtt could be vastly underestimated.

   To avoid spurious inferences, ignore a segment as invalid if any of
   its sequence range has been retransmitted before and if either of two
   conditions is true:

   1.  The Timestamp Echo Reply field (TSecr) of the ACK&#x27;s timestamp
       option [<a href="/doc/html/rfc7323" title="&quot;TCP Extensions for High Performance&quot;">RFC7323</a>], if available, indicates the ACK was not
       acknowledging the last retransmission of the segment.

   2.  The segment was last retransmitted less than RACK.min_rtt ago.

   The second check is a heuristic when the TCP Timestamp option is not
   available or when the round-trip time is less than the TCP Timestamp
   clock granularity.

   Among all the segments newly ACKed or SACKed by this ACK that pass
   the checks above, update the RACK.rtt to be the RTT sample calculated
   using this ACK.  Furthermore, record the most recent Segment.xmit_ts
   in RACK.xmit_ts if it is ahead of RACK.xmit_ts.  If Segment.xmit_ts
   equals RACK.xmit_ts (e.g., due to clock granularity limits), then
   compare Segment.end_seq and RACK.end_seq to break the tie when
   deciding whether to update the RACK.segment&#x27;s associated state.

   Step 2 may be summarized in pseudocode as:

   RACK_sent_after(t1, seq1, t2, seq2):
       If t1 &gt; t2:
           Return true
       Else if t1 == t2 AND seq1 &gt; seq2:
           Return true
       Else:
           Return false

   RACK_update():
       For each Segment newly acknowledged, cumulatively or selectively,
       in ascending order of Segment.xmit_ts:
           rtt = Now() - Segment.xmit_ts
           If Segment.retransmitted is TRUE:
               If ACK.ts_option.echo_reply &lt; Segment.xmit_ts:
                  Continue
               If rtt &lt; RACK.min_rtt:
                  Continue

           RACK.rtt = rtt
           If RACK_sent_after(Segment.xmit_ts, Segment.end_seq
                              RACK.xmit_ts, RACK.end_seq):
               RACK.xmit_ts = Segment.xmit_ts
               RACK.end_seq = Segment.end_seq

   Step 3: Detect data segment reordering.

   To detect reordering, the sender looks for original data segments
   being delivered out of order.  To detect such cases, the sender
   tracks the highest sequence selectively or cumulatively acknowledged
   in the RACK.fack variable. &quot;.fack&quot; stands for the most &quot;Forward ACK&quot;
   (this term is adopted from [<a href="#ref-FACK" title="&quot;Forward acknowledgement: refining TCP congestion control&quot;">FACK</a>]).  If a never-retransmitted segment
   that&#x27;s below RACK.fack is (selectively or cumulatively) acknowledged,
   it has been delivered out of order.  The sender sets
   RACK.reordering_seen to TRUE if such a segment is identified.

   RACK_detect_reordering():
       For each Segment newly acknowledged, cumulatively or selectively,
       in ascending order of Segment.end_seq:
           If Segment.end_seq &gt; RACK.fack:
               RACK.fack = Segment.end_seq
           Else if Segment.end_seq &lt; RACK.fack AND
                   Segment.retransmitted is FALSE:
               RACK.reordering_seen = TRUE

   Step 4: Update the RACK reordering window.

   The RACK reordering window, RACK.reo_wnd, serves as an adaptive
   allowance for settling time before marking a segment as lost.  This
   step documents a detailed algorithm that follows the principles
   outlined in the &quot;Reordering Window Adaptation&quot; section.

   If no reordering has been observed based on the previous step, then
   one way the sender can enter fast recovery is when the number of
   SACKed segments matches or exceeds DupThresh (similar to [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>]).
   Furthermore, when no reordering has been observed, the RACK.reo_wnd
   is set to 0 both upon entering and during fast recovery or RTO
   recovery.

   Otherwise, if some reordering has been observed, then RACK does not
   trigger fast recovery based on DupThresh.

   Whether or not reordering has been observed, RACK uses the reordering
   window to assess whether any segments can be marked as lost.  As a
   consequence, the sender also enters fast recovery when there are any
   number of SACKed segments, as long as the reorder window has passed
   for some non-SACKed segments.

   When the reordering window is not set to 0, it starts with a
   conservative RACK.reo_wnd of RACK.min_RTT/4.  This value was chosen
   because Linux TCP used the same factor in its implementation to delay
   Early Retransmit [<a href="/doc/html/rfc5827" title="&quot;Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP)&quot;">RFC5827</a>] to reduce spurious loss detections in the
   presence of reordering, and experience showed this worked reasonably
   well [<a href="#ref-DMCG11" title="&quot;Proportional Rate Reduction for TCP&quot;">DMCG11</a>].

   However, the reordering detection in the previous step, Step 3, has a
   self-reinforcing drawback when the reordering window is too small to
   cope with the actual reordering.  When that happens, RACK could
   spuriously mark reordered segments as lost, causing them to be
   retransmitted.  In turn, the retransmissions can prevent the
   necessary conditions for Step 3 to detect reordering since this
   mechanism requires ACKs or SACKs only for segments that have never
   been retransmitted.  In some cases, such scenarios can persist,
   causing RACK to continue to spuriously mark segments as lost without
   realizing the reordering window is too small.

   To avoid the issue above, RACK dynamically adapts to higher degrees
   of reordering using DSACK options from the receiver.  Receiving an
   ACK with a DSACK option indicates a possible spurious retransmission,
   suggesting that RACK.reo_wnd may be too small.  The RACK.reo_wnd
   increases linearly for every round trip in which the sender receives
   some DSACK option so that after N round trips in which a DSACK is
   received, the RACK.reo_wnd becomes (N+1) * min_RTT / 4, with an
   upper-bound of SRTT.

   If the reordering is temporary, then a large adapted reordering
   window would unnecessarily delay loss recovery later.  Therefore,
   RACK persists using the inflated RACK.reo_wnd for up to 16 loss
   recoveries, after which it resets RACK.reo_wnd to its starting value,
   min_RTT / 4.  The downside of resetting the reordering window is the
   risk of triggering spurious fast recovery episodes if the reordering
   remains high.  The rationale for this approach is to bound such
   spurious recoveries to approximately once every 16 recoveries (less
   than 7%).

   To track the linear scaling factor for the adaptive reordering
   window, RACK uses the variable RACK.reo_wnd_mult, which is
   initialized to 1 and adapts with the observed reordering.

   The following pseudocode implements the above algorithm for updating
   the RACK reordering window:

   RACK_update_reo_wnd():

       /* DSACK-based reordering window adaptation */
       If RACK.dsack_round is not None AND
          SND.UNA &gt;= RACK.dsack_round:
           RACK.dsack_round = None
       /* Grow the reordering window per round that sees DSACK.
          Reset the window after 16 DSACK-free recoveries */
       If RACK.dsack_round is None AND
          any DSACK option is present on latest received ACK:
           RACK.dsack_round = SND.NXT
           RACK.reo_wnd_mult += 1
           RACK.reo_wnd_persist = 16
       Else if exiting Fast or RTO recovery:
           RACK.reo_wnd_persist -= 1
           If RACK.reo_wnd_persist &lt;= 0:
               RACK.reo_wnd_mult = 1

       If RACK.reordering_seen is FALSE:
           If in Fast or RTO recovery:
               Return 0
           Else if RACK.segs_sacked &gt;= DupThresh:
               Return 0
       Return min(RACK.reo_wnd_mult * RACK.min_RTT / 4, SRTT)

   Step 5: Detect losses.

   For each segment that has not been SACKed, RACK considers that
   segment lost if another segment that was sent later has been
   delivered and the reordering window has passed.  RACK considers the
   reordering window to have passed if the RACK.segment was sent a
   sufficient time after the segment in question, if a sufficient time
   has elapsed since the RACK.segment was S/ACKed, or some combination
   of the two.  More precisely, RACK marks a segment as lost if:

    RACK.xmit_ts &gt;= Segment.xmit_ts
           AND
    RACK.xmit_ts - Segment.xmit_ts + (now - RACK.ack_ts) &gt;= RACK.reo_wnd

   Solving this second condition for &quot;now&quot;, the moment at which a
   segment is marked as lost, yields:

   now &gt;= Segment.xmit_ts + RACK.reo_wnd + (RACK.ack_ts - RACK.xmit_ts)

   Then (RACK.ack_ts - RACK.xmit_ts) is the round-trip time of the most
   recently (re)transmitted segment that&#x27;s been delivered.  When
   segments are delivered in order, the most recently (re)transmitted
   segment that&#x27;s been delivered is also the most recently delivered;
   hence, RACK.rtt == RACK.ack_ts - RACK.xmit_ts.  But if segments were
   reordered, then the segment delivered most recently was sent before
   the most recently (re)transmitted segment.  Hence, RACK.rtt &gt;
   (RACK.ack_ts - RACK.xmit_ts).

   Since RACK.RTT &gt;= (RACK.ack_ts - RACK.xmit_ts), the previous equation
   reduces to saying that the sender can declare a segment lost when:

   now &gt;= Segment.xmit_ts + RACK.reo_wnd + RACK.rtt

   In turn, that is equivalent to stating that a RACK sender should
   declare a segment lost when:

   Segment.xmit_ts + RACK.rtt + RACK.reo_wnd - now &lt;= 0

   Note that if the value on the left-hand side is positive, it
   represents the remaining wait time before the segment is deemed lost.
   But this risks a timeout (RTO) if no more ACKs come back (e.g., due
   to losses or application-limited transmissions) to trigger the
   marking.  For timely loss detection, it is RECOMMENDED that the
   sender install a reordering timer.  This timer expires at the
   earliest moment when RACK would conclude that all the unacknowledged
   segments within the reordering window were lost.

   The following pseudocode implements the algorithm above.  When an ACK
   is received or the RACK reordering timer expires, call
   RACK_detect_loss_and_arm_timer().  The algorithm breaks timestamp
   ties by using the TCP sequence space since high-speed networks often
   have multiple segments with identical timestamps.

   RACK_detect_loss():
       timeout = 0
       RACK.reo_wnd = RACK_update_reo_wnd()
       For each segment, Segment, not acknowledged yet:
           If RACK_sent_after(RACK.xmit_ts, RACK.end_seq,
                              Segment.xmit_ts, Segment.end_seq):
               remaining = Segment.xmit_ts + RACK.rtt +
                           RACK.reo_wnd - Now()
               If remaining &lt;= 0:
                   Segment.lost = TRUE
                   Segment.xmit_ts = INFINITE_TS
               Else:
                   timeout = max(remaining, timeout)
       Return timeout

   RACK_detect_loss_and_arm_timer():
       timeout = RACK_detect_loss()
       If timeout != 0
           Arm the RACK timer to call
           RACK_detect_loss_and_arm_timer() after timeout

   As an optimization, an implementation can choose to check only
   segments that have been sent before RACK.xmit_ts.  This can be more
   efficient than scanning the entire SACK scoreboard, especially when
   there are many segments in flight.  The implementation can use a
   separate doubly linked list ordered by Segment.xmit_ts, insert a
   segment at the tail of the list when it is (re)transmitted, and
   remove a segment from the list when it is delivered or marked as
   lost.  In Linux TCP, this optimization improved CPU usage by orders
   of magnitude during some fast recovery episodes on high-speed WAN
   networks.

<span class="h3"><a class="selflink" id="section-6.3" href="#section-6.3">6.3</a>.  Upon RTO Expiration</span>

   Upon RTO timer expiration, RACK marks the first outstanding segment
   as lost (since it was sent an RTO ago); for all the other segments,
   RACK only marks the segment as lost if the time elapsed since the
   segment was transmitted is at least the sum of the recent RTT and the
   reordering window.

   RACK_mark_losses_on_RTO():
       For each segment, Segment, not acknowledged yet:
           If SEG.SEQ == SND.UNA OR
              Segment.xmit_ts + RACK.rtt + RACK.reo_wnd - Now() &lt;= 0:
               Segment.lost = TRUE

<span class="h2"><a class="selflink" id="section-7" href="#section-7">7</a>.  TLP Algorithm Details</span>

<span class="h3"><a class="selflink" id="section-7.1" href="#section-7.1">7.1</a>.  Initializing State</span>

   Reset TLP.is_retrans and TLP.end_seq when initiating a connection,
   fast recovery, or RTO recovery.

   TLP_init():
       TLP.end_seq = None
       TLP.is_retrans = false

<span class="h3"><a class="selflink" id="section-7.2" href="#section-7.2">7.2</a>.  Scheduling a Loss Probe</span>

   The sender schedules a loss probe timeout (PTO) to transmit a segment
   during the normal transmission process.  The sender SHOULD start or
   restart a loss probe PTO timer after transmitting new data (that was
   not itself a loss probe) or upon receiving an ACK that cumulatively
   acknowledges new data unless it is already in fast recovery, RTO
   recovery, or segments have been SACKed (i.e., RACK.segs_sacked is not
   zero).  These conditions are excluded because they are addressed by
   similar mechanisms, like Limited Transmit [<a href="/doc/html/rfc3042" title="&quot;Enhancing TCP&#x27;s Loss Recovery Using Limited Transmit&quot;">RFC3042</a>], the RACK
   reordering timer, and Forward RTO-Recovery (F-RTO) [<a href="/doc/html/rfc5682" title="&quot;Forward RTO-Recovery (F-RTO): An Algorithm for Detecting Spurious Retransmission Timeouts with TCP&quot;">RFC5682</a>].

   The sender calculates the PTO interval by taking into account a
   number of factors.

   First, the default PTO interval is 2*SRTT.  By that time, it is
   prudent to declare that an ACK is overdue since under normal
   circumstances, i.e., no losses, an ACK typically arrives in one SRTT.
   Choosing the PTO to be exactly an SRTT would risk causing spurious
   probes given that network and end-host delay variance can cause an
   ACK to be delayed beyond the SRTT.  Hence, the PTO is conservatively
   chosen to be the next integral multiple of SRTT.

   Second, when there is no SRTT estimate available, the PTO SHOULD be 1
   second.  This conservative value corresponds to the RTO value when no
   SRTT is available, per [<a href="/doc/html/rfc6298" title="&quot;Computing TCP&#x27;s Retransmission Timer&quot;">RFC6298</a>].

   Third, when the FlightSize is one segment, the sender MAY inflate the
   PTO by TLP.max_ack_delay to accommodate a potentially delayed
   acknowledgment and reduce the risk of spurious retransmissions.  The
   actual value of TLP.max_ack_delay is implementation specific.

   Finally, if the time at which an RTO would fire (here denoted as
   &quot;TCP_RTO_expiration()&quot;) is sooner than the computed time for the PTO,
   then the sender schedules a TLP to be sent at that RTO time.

   Summarizing these considerations in pseudocode form, a sender SHOULD
   use the following logic to select the duration of a PTO:

   TLP_calc_PTO():
       If SRTT is available:
           PTO = 2 * SRTT
           If FlightSize is one segment:
              PTO += TLP.max_ack_delay
       Else:
           PTO = 1 sec

       If Now() + PTO &gt; TCP_RTO_expiration():
           PTO = TCP_RTO_expiration() - Now()

<span class="h3"><a class="selflink" id="section-7.3" href="#section-7.3">7.3</a>.  Sending a Loss Probe upon PTO Expiration</span>

   When the PTO timer expires, the sender MUST check whether both of the
   following conditions are met before sending a loss probe:

   1.  First, there is no other previous loss probe still in flight.
       This ensures that, at any given time, the sender has at most one
       additional packet in flight beyond the congestion window limit.
       This invariant is maintained using the state variable
       TLP.end_seq, which indicates the latest unacknowledged TLP loss
       probe&#x27;s ending sequence.  It is reset when the loss probe has
       been acknowledged or is deemed lost or irrelevant.

   2.  Second, the sender has obtained an RTT measurement since the last
       loss probe transmission or the start of the connection, whichever
       was later.  This condition ensures that loss probe
       retransmissions do not prevent taking the RTT samples necessary
       to adapt SRTT to an increase in path RTT.

   If either one of these two conditions is not met, then the sender
   MUST skip sending a loss probe and MUST proceed to re-arm the RTO
   timer, as specified at the end of this section.

   If both conditions are met, then the sender SHOULD transmit a
   previously unsent data segment, if one exists and the receive window
   allows, and increment the FlightSize accordingly.  Note that the
   FlightSize could be one packet greater than the congestion window
   temporarily until the next ACK arrives.

   If such an unsent segment is not available, then the sender SHOULD
   retransmit the highest-sequence segment sent so far and set
   TLP.is_retrans to true.  This segment is chosen to deal with the
   retransmission ambiguity problem in TCP.  Suppose a sender sends N
   segments and then retransmits the last segment (segment N) as a loss
   probe, after which the sender receives a SACK for segment N.  As long
   as the sender waits for the RACK reordering window to expire, it
   doesn&#x27;t matter if that SACK was for the original transmission of
   segment N or the TLP retransmission; in either case, the arrival of
   the SACK for segment N provides evidence that the N-1 segments
   preceding segment N were likely lost.

   In a case where there is only one original outstanding segment of
   data (N=1), the same logic (trivially) applies: an ACK for a single
   outstanding segment tells the sender that the N-1=0 segments
   preceding that segment were lost.  Furthermore, whether there are N&gt;1
   or N=1 outstanding segments, there is a question about whether the
   original last segment or its TLP retransmission were lost; the sender
   estimates whether there was such a loss using TLP recovery detection
   (see below).

   The sender MUST follow the RACK transmission procedures in the &quot;Upon
   Transmitting a Data Segment&quot; section upon sending either a
   retransmission or a new data loss probe.  This is critical for
   detecting losses using the ACK for the loss probe.

   After attempting to send a loss probe, regardless of whether a loss
   probe was sent, the sender MUST re-arm the RTO timer, not the PTO
   timer, if the FlightSize is not zero.  This ensures RTO recovery
   remains the last resort if TLP fails.  The following pseudocode
   summarizes the operations.

   TLP_send_probe():

       If TLP.end_seq is None and
          Sender has taken a new RTT sample since last probe or
          the start of connection:
           TLP.is_retrans = false
           Segment = send buffer segment starting at SND.NXT
           If Segment exists and fits the peer receive window limit:
              /* Transmit the lowest-sequence unsent Segment */
              Transmit Segment
              RACK_transmit_data(Segment)
              TLP.end_seq = SND.NXT
              Increase FlightSize by Segment length
           Else:
              /* Retransmit the highest-sequence Segment sent */
              Segment = send buffer segment ending at SND.NXT
              Transmit Segment
              RACK_retransmit_data(Segment)
              TLP.end_seq = SND.NXT
              TLP.is_retrans = true

       If FlightSize is not zero:
           Rearm RTO timer to fire at timeout = now + RTO

<span class="h3"><a class="selflink" id="section-7.4" href="#section-7.4">7.4</a>.  Detecting Losses Using the ACK of the Loss Probe</span>

   When there is packet loss in a flight ending with a loss probe, the
   feedback solicited by a loss probe will reveal one of two scenarios,
   depending on the pattern of losses.

<span class="h4"><a class="selflink" id="section-7.4.1" href="#section-7.4.1">7.4.1</a>.  General Case: Detecting Packet Losses Using RACK</span>

   If the loss probe and the ACK that acknowledges the probe are
   delivered successfully, RACK-TLP uses this ACK -- just as it would
   with any other ACK -- to detect if any segments sent prior to the
   probe were dropped.  RACK would typically infer that any
   unacknowledged data segments sent before the loss probe were lost,
   since they were sent sufficiently far in the past (where at least one
   PTO has elapsed, plus one round trip for the loss probe to be ACKed).
   More specifically, RACK_detect_loss() (Step 5) would mark those
   earlier segments as lost.  Then the sender would trigger a fast
   recovery to recover those losses.

<span class="h4"><a class="selflink" id="section-7.4.2" href="#section-7.4.2">7.4.2</a>.  Special Case: Detecting a Single Loss Repaired by the Loss Probe</span>

   If the TLP retransmission repairs all the lost in-flight sequence
   ranges (i.e., only the last segment in the flight was lost), the ACK
   for the loss probe appears to be a regular cumulative ACK, which
   would not normally trigger the congestion control response to this
   packet loss event.  The following TLP recovery detection mechanism
   examines ACKs to detect this special case to make congestion control
   respond properly [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>].

   After a TLP retransmission, the sender checks for this special case
   of a single loss that is recovered by the loss probe itself.  To
   accomplish this, the sender checks for a duplicate ACK or DSACK
   indicating that both the original segment and TLP retransmission
   arrived at the receiver, which means there was no loss.  If the TLP
   sender does not receive such an indication, then it MUST assume that
   the original data segment, the TLP retransmission, or a corresponding
   ACK was lost for congestion control purposes.

   If the TLP retransmission is spurious, a receiver that uses DSACK
   would return an ACK that covers TLP.end_seq with a DSACK option (Case
   1).  If the receiver does not support DSACK, it would return a DupAck
   without any SACK option (Case 2).  If the sender receives an ACK
   matching either case, then the sender estimates that the receiver
   received both the original data segment and the TLP probe
   retransmission.  The sender considers the TLP episode to be done and
   records that fact by setting TLP.end_seq to None.

   Upon receiving an ACK that covers some sequence number after
   TLP.end_seq, the sender should have received any ACKs for the
   original segment and TLP probe retransmission segment.  At that time,
   if the TLP.end_seq is still set and thus indicates that the TLP probe
   retransmission remains unacknowledged, then the sender should presume
   that at least one of its data segments was lost.  The sender then
   SHOULD invoke a congestion control response equivalent to a fast
   recovery.

   More precisely, on each ACK, the sender executes the following:

   TLP_process_ack(ACK):
       If TLP.end_seq is not None AND ACK&#x27;s ack. number &gt;= TLP.end_seq:
           If not TLP.is_retrans:
               TLP.end_seq = None    /* TLP of new data delivered */
           Else if ACK has a DSACK option matching TLP.end_seq:
               TLP.end_seq = None    /* Case 1, above */
           Else If ACK&#x27;s ack. number &gt; TLP.end_seq:
               TLP.end_seq = None    /* Repaired the single loss */
               (Invoke congestion control to react to
                the loss event the probe has repaired)
           Else If ACK is a DupAck without any SACK option:
               TLP.end_seq = None     /* Case 2, above */

<span class="h2"><a class="selflink" id="section-8" href="#section-8">8</a>.  Managing RACK-TLP Timers</span>

   The RACK reordering timer, the TLP PTO timer, the RTO, and Zero
   Window Probe (ZWP) timer [<a href="/doc/html/rfc793" title="&quot;Transmission Control Protocol&quot;">RFC793</a>] are mutually exclusive and are used
   in different scenarios.  When arming a RACK reordering timer or TLP
   PTO timer, the sender SHOULD cancel any other pending timers.  An
   implementation is expected to have one timer with an additional state
   variable indicating the type of the timer.

<span class="h2"><a class="selflink" id="section-9" href="#section-9">9</a>.  Discussion</span>

<span class="h3"><a class="selflink" id="section-9.1" href="#section-9.1">9.1</a>.  Advantages and Disadvantages</span>

   The biggest advantage of RACK-TLP is that every data segment, whether
   it is an original data transmission or a retransmission, can be used
   to detect losses of the segments sent chronologically prior to it.
   This enables RACK-TLP to use fast recovery in cases with application-
   limited flights of data, lost retransmissions, or data segment
   reordering events.  Consider the following examples:

   1.  Packet drops at the end of an application data flight: Consider a
       sender that transmits an application-limited flight of three data
       segments (P1, P2, P3), and P1 and P3 are lost.  Suppose the
       transmission of each segment is at least RACK.reo_wnd after the
       transmission of the previous segment.  RACK will mark P1 as lost
       when the SACK of P2 is received, and this will trigger the
       retransmission of P1 as R1.  When R1 is cumulatively
       acknowledged, RACK will mark P3 as lost, and the sender will
       retransmit P3 as R3.  This example illustrates how RACK is able
       to repair certain drops at the tail of a transaction without an
       RTO recovery.  Notice that neither the conventional duplicate ACK
       threshold [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>], nor the loss recovery algorithm [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>],
       nor the Forward Acknowledgment [<a href="#ref-FACK" title="&quot;Forward acknowledgement: refining TCP congestion control&quot;">FACK</a>] algorithm can detect such
       losses because of the required segment or sequence count.

   2.  Lost retransmission: Consider a flight of three data segments
       (P1, P2, P3) that are sent; P1 and P2 are dropped.  Suppose the
       transmission of each segment is at least RACK.reo_wnd after the
       transmission of the previous segment.  When P3 is SACKed, RACK
       will mark P1 and P2 as lost, and they will be retransmitted as R1
       and R2.  Suppose R1 is lost again but R2 is SACKed; RACK will
       mark R1 as lost and trigger retransmission again.  Again, neither
       the conventional three-duplicate ACK threshold approach, nor the
       loss recovery algorithm [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>], nor the Forward Acknowledgment
       [<a href="#ref-FACK" title="&quot;Forward acknowledgement: refining TCP congestion control&quot;">FACK</a>] algorithm can detect such losses.  And such a lost
       retransmission can happen when TCP is being rate-limited,
       particularly by token bucket policers with a large bucket depth
       and low rate limit; in such cases, retransmissions are often lost
       repeatedly because standard congestion control requires multiple
       round trips to reduce the rate below the policed rate.

   3.  Packet reordering: Consider a simple reordering event where a
       flight of segments are sent as (P1, P2, P3).  P1 and P2 carry a
       full payload of Maximum Sender Size (MSS) octets, but P3 has only
       a 1-octet payload.  Suppose the sender has detected reordering
       previously and thus RACK.reo_wnd is min_RTT/4.  Now P3 is
       reordered and delivered first, before P1 and P2.  As long as P1
       and P2 are delivered within min_RTT/4, RACK will not consider P1
       and P2 lost.  But if P1 and P2 are delivered outside the
       reordering window, then RACK will still spuriously mark P1 and P2
       as lost.

   The examples above show that RACK-TLP is particularly useful when the
   sender is limited by the application, which can happen with
   interactive or request/response traffic.  Similarly, RACK still works
   when the sender is limited by the receive window, which can happen
   with applications that use the receive window to throttle the sender.

   RACK-TLP works more efficiently with TCP Segmentation Offload (TSO)
   compared to DupAck counting.  RACK always marks the entire TSO
   aggregate as lost because the segments in the same TSO aggregate have
   the same transmission timestamp.  By contrast, the algorithms based
   on sequence counting (e.g., [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>], [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>]) may mark only a
   subset of segments in the TSO aggregate as lost, forcing the stack to
   perform expensive fragmentation of the TSO aggregate or to
   selectively tag individual segments as lost in the scoreboard.

   The main drawback of RACK-TLP is the additional state required
   compared to DupAck counting.  RACK requires the sender to record the
   transmission time of each segment sent at a clock granularity that is
   finer than 1/4 of the minimum RTT of the connection.  TCP
   implementations that already record this for RTT estimation do not
   require any new per-packet state.  But implementations that are not
   yet recording segment transmission times will need to add per-packet
   internal state (expected to be either 4 or 8 octets per segment or
   TSO aggregate) to track transmission times.  In contrast, the loss
   detection approach described in [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>] does not require any per-
   packet state beyond the SACK scoreboard; this is particularly useful
   on ultra-low RTT networks where the RTT may be less than the sender
   TCP clock granularity (e.g., inside data centers).  Another
   disadvantage is that the reordering timer may expire prematurely
   (like any other retransmission timer) and cause higher spurious
   retransmissions, especially if DSACK is not supported.

<span class="h3"><a class="selflink" id="section-9.2" href="#section-9.2">9.2</a>.  Relationships with Other Loss Recovery Algorithms</span>

   The primary motivation of RACK-TLP is to provide a general
   alternative to some of the standard loss recovery algorithms
   [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>] [<a href="/doc/html/rfc5827" title="&quot;Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP)&quot;">RFC5827</a>] [<a href="/doc/html/rfc4653" title="&quot;Improving the Robustness of TCP to Non- Congestion Events&quot;">RFC4653</a>].  In particular, the SACK
   loss recovery algorithm for TCP [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>] is not designed to handle
   lost retransmissions, so its NextSeg() does not work for lost
   retransmissions, and it does not specify the corresponding required
   additional congestion response.  Therefore, the algorithm [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>]
   MUST NOT be used with RACK-TLP; instead, a modified recovery
   algorithm that carefully addresses such a case is needed.

   The Early Retransmit mechanism [<a href="/doc/html/rfc5827" title="&quot;Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP)&quot;">RFC5827</a>] and NCR for TCP [<a href="/doc/html/rfc4653" title="&quot;Improving the Robustness of TCP to Non- Congestion Events&quot;">RFC4653</a>]
   dynamically adjust the duplicate ACK threshold based on the current
   or previous flight sizes.  RACK-TLP takes a different approach by
   using a time-based reordering window.  RACK-TLP can be seen as an
   extended Early Retransmit [<a href="/doc/html/rfc5827" title="&quot;Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP)&quot;">RFC5827</a>] without a FlightSize limit but
   with an additional reordering window.  [<a href="#ref-FACK" title="&quot;Forward acknowledgement: refining TCP congestion control&quot;">FACK</a>] considers an original
   segment to be lost when its sequence range is sufficiently far below
   the highest SACKed sequence.  In some sense, RACK-TLP can be seen as
   a generalized form of FACK that operates in time space instead of
   sequence space, enabling it to better handle reordering, application-
   limited traffic, and lost retransmissions.

   RACK-TLP is compatible with the standard RTO [<a href="/doc/html/rfc6298" title="&quot;Computing TCP&#x27;s Retransmission Timer&quot;">RFC6298</a>], RTO Restart
   [<a href="/doc/html/rfc7765" title="&quot;TCP and Stream Control Transmission Protocol (SCTP) RTO Restart&quot;">RFC7765</a>], F-RTO [<a href="/doc/html/rfc5682" title="&quot;Forward RTO-Recovery (F-RTO): An Algorithm for Detecting Spurious Retransmission Timeouts with TCP&quot;">RFC5682</a>], and Eifel algorithms [<a href="/doc/html/rfc3522" title="&quot;The Eifel Detection Algorithm for TCP&quot;">RFC3522</a>].  This is
   because RACK-TLP only detects loss by using ACK events.  It neither
   changes the RTO timer calculation nor detects spurious RTOs.  RACK-
   TLP slightly changes the behavior of [<a href="/doc/html/rfc6298" title="&quot;Computing TCP&#x27;s Retransmission Timer&quot;">RFC6298</a>] by preceding the RTO
   with a TLP and reducing potential spurious retransmissions after RTO.

<span class="h3"><a class="selflink" id="section-9.3" href="#section-9.3">9.3</a>.  Interaction with Congestion Control</span>

   RACK-TLP intentionally decouples loss detection from congestion
   control.  RACK-TLP only detects losses; it does not modify the
   congestion control algorithm [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] [<a href="/doc/html/rfc6937" title="&quot;Proportional Rate Reduction for TCP&quot;">RFC6937</a>].  A segment marked
   as lost by RACK-TLP MUST NOT be retransmitted until congestion
   control deems this appropriate.  As mentioned in the paragraph
   following Figure 1 (<a href="#section-3.4">Section 3.4</a>, Paragraph 3), [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] mandates a
   principle that loss in two successive windows of data or the loss of
   a retransmission must be taken as two indications of congestion and
   therefore trigger two separate reactions.  The Proportional Rate
   Reduction (PRR) algorithm [<a href="/doc/html/rfc6937" title="&quot;Proportional Rate Reduction for TCP&quot;">RFC6937</a>] is RECOMMENDED for the specific
   congestion control actions taken upon the losses detected by RACK-
   TLP.  In the absence of PRR [<a href="/doc/html/rfc6937" title="&quot;Proportional Rate Reduction for TCP&quot;">RFC6937</a>], when RACK-TLP detects a lost
   retransmission, the congestion control MUST trigger an additional
   congestion response per the aforementioned principle in [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>].
   If multiple original transmissions or retransmissions were lost in a
   window, the congestion control specified in [<a href="/doc/html/rfc5681" title="&quot;TCP Congestion Control&quot;">RFC5681</a>] only reacts
   once per window.  The congestion control implementer is advised to
   carefully consider this subtle situation introduced by RACK-TLP.

   The only exception -- the only way in which RACK-TLP modulates the
   congestion control algorithm -- is that one outstanding loss probe
   can be sent even if the congestion window is fully used.  However,
   this temporary overcommit is accounted for and credited in the in-
   flight data tracked for congestion control, so that congestion
   control will erase the overcommit upon the next ACK.

   If packet losses happen after reordering has been observed, RACK-TLP
   may take longer to detect losses than the pure DupAck counting
   approach.  In this case, TCP may continue to increase the congestion
   window upon receiving ACKs during this time, making the sender more
   aggressive.

   The following simple example compares how RACK-TLP and non-RACK-TLP
   loss detection interact with congestion control: suppose a sender has
   a congestion window (cwnd) of 20 segments on a SACK-enabled
   connection.  It sends 10 data segments, and all of them are lost.

   Without RACK-TLP, the sender would time out, reset cwnd to 1, and
   retransmit the first segment.  It would take four round trips (1 + 2
   + 4 + 3 = 10) to retransmit all the 10 lost segments using slow
   start.  The recovery latency would be RTO + 4*RTT, with an ending
   cwnd of 4 segments due to congestion window validation.

   With RACK-TLP, a sender would send the TLP after 2*RTT and get a
   DupAck, enabling RACK to detect the losses and trigger fast recovery.
   If the sender implements Proportional Rate Reduction [<a href="/doc/html/rfc6937" title="&quot;Proportional Rate Reduction for TCP&quot;">RFC6937</a>], it
   would slow start to retransmit the remaining 9 lost segments since
   the number of segments in flight (0) is lower than the slow start
   threshold (10).  The slow start would again take four round trips (1
   + 2 + 4 + 3 = 10) to retransmit all the lost segments.  The recovery
   latency would be 2*RTT + 4*RTT, with an ending cwnd set to the slow-
   start threshold of 10 segments.

   The difference in recovery latency (RTO + 4*RTT vs 6*RTT) can be
   significant if the RTT is much smaller than the minimum RTO (1 second
   in [<a href="/doc/html/rfc6298" title="&quot;Computing TCP&#x27;s Retransmission Timer&quot;">RFC6298</a>]) or if the RTT is large.  The former case can happen in
   local area networks, data center networks, or content distribution
   networks with deep deployments.  The latter case can happen in
   developing regions with highly congested and/or high-latency
   networks.

<span class="h3"><a class="selflink" id="section-9.4" href="#section-9.4">9.4</a>.  TLP Recovery Detection with Delayed ACKs</span>

   Delayed or stretched ACKs complicate the detection of repairs done by
   TLP since, with such ACKs, the sender takes a longer time to receive
   fewer ACKs than would normally be expected.  To mitigate this
   complication, before sending a TLP loss probe retransmission, the
   sender should attempt to wait long enough that the receiver has sent
   any delayed ACKs that it is withholding.  The sender algorithm
   described above features such a delay in the form of
   TLP.max_ack_delay.  Furthermore, if the receiver supports DSACK,
   then, in the case of a delayed ACK, the sender&#x27;s TLP recovery
   detection mechanism (see above) can use the DSACK information to
   infer that the original and TLP retransmission both arrived at the
   receiver.

   If there is ACK loss or a delayed ACK without a DSACK, then this
   algorithm is conservative because the sender will reduce the
   congestion window when, in fact, there was no packet loss.  In
   practice, this is acceptable and potentially even desirable: if there
   is reverse path congestion, then reducing the congestion window can
   be prudent.

<span class="h3"><a class="selflink" id="section-9.5" href="#section-9.5">9.5</a>.  RACK-TLP for Other Transport Protocols</span>

   RACK-TLP can be implemented in other transport protocols (e.g.,
   [<a href="#ref-QUIC-LR" title="&quot;QUIC Loss Detection and Congestion Control&quot;">QUIC-LR</a>]).  The [<a href="#ref-SPROUT" title="&quot;Stochastic Forecasts Achieve High Throughput and Low Delay over Cellular Networks&quot;">SPROUT</a>] loss detection algorithm was also
   independently designed to use a 10 ms reordering window to improve
   its loss detection similar to RACK.

<span class="h2"><a class="selflink" id="section-10" href="#section-10">10</a>.  Security Considerations</span>

   RACK-TLP algorithm behavior is based on information conveyed in SACK
   options, so it has security considerations similar to those described
   in the Security Considerations section of [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>].

   Additionally, RACK-TLP has a lower risk profile than the loss
   recovery algorithm [<a href="/doc/html/rfc6675" title="&quot;A Conservative Loss Recovery Algorithm Based on Selective Acknowledgment (SACK) for TCP&quot;">RFC6675</a>] because it is not vulnerable to ACK-
   splitting attacks [<a href="#ref-SCWA99" title="&quot;TCP congestion control with a misbehaving receiver&quot;">SCWA99</a>]: for an MSS-sized segment sent, the
   receiver or the attacker might send MSS ACKs that selectively or
   cumulatively acknowledge one additional byte per ACK.  This would not
   fool RACK.  In such a scenario, RACK.xmit_ts would not advance
   because all the sequence ranges within the segment were transmitted
   at the same time and thus carry the same transmission timestamp.  In
   other words, SACKing only one byte of a segment or SACKing the
   segment in entirety have the same effect with RACK.

<span class="h2"><a class="selflink" id="section-11" href="#section-11">11</a>.  IANA Considerations</span>

   This document has no IANA actions.

<span class="h2"><a class="selflink" id="section-12" href="#section-12">12</a>.  References</span>

<span class="h3"><a class="selflink" id="section-12.1" href="#section-12.1">12.1</a>.  Normative References</span>

   [<a id="ref-RFC2018">RFC2018</a>]  Mathis, M., Mahdavi, J., Floyd, S., and A. Romanow, &quot;TCP
              Selective Acknowledgment Options&quot;, <a href="/doc/html/rfc2018">RFC 2018</a>,
              DOI 10.17487/RFC2018, October 1996,
              &lt;<a href="https://www.rfc-editor.org/info/rfc2018">https://www.rfc-editor.org/info/rfc2018</a>&gt;.

   [<a id="ref-RFC2119">RFC2119</a>]  Bradner, S., &quot;Key words for use in RFCs to Indicate
              Requirement Levels&quot;, <a href="/doc/html/bcp14">BCP 14</a>, <a href="/doc/html/rfc2119">RFC 2119</a>,
              DOI 10.17487/RFC2119, March 1997,
              &lt;<a href="https://www.rfc-editor.org/info/rfc2119">https://www.rfc-editor.org/info/rfc2119</a>&gt;.

   [<a id="ref-RFC2883">RFC2883</a>]  Floyd, S., Mahdavi, J., Mathis, M., and M. Podolsky, &quot;An
              Extension to the Selective Acknowledgement (SACK) Option
              for TCP&quot;, <a href="/doc/html/rfc2883">RFC 2883</a>, DOI 10.17487/RFC2883, July 2000,
              &lt;<a href="https://www.rfc-editor.org/info/rfc2883">https://www.rfc-editor.org/info/rfc2883</a>&gt;.

   [<a id="ref-RFC5681">RFC5681</a>]  Allman, M., Paxson, V., and E. Blanton, &quot;TCP Congestion
              Control&quot;, <a href="/doc/html/rfc5681">RFC 5681</a>, DOI 10.17487/RFC5681, September 2009,
              &lt;<a href="https://www.rfc-editor.org/info/rfc5681">https://www.rfc-editor.org/info/rfc5681</a>&gt;.

   [<a id="ref-RFC6298">RFC6298</a>]  Paxson, V., Allman, M., Chu, J., and M. Sargent,
              &quot;Computing TCP&#x27;s Retransmission Timer&quot;, <a href="/doc/html/rfc6298">RFC 6298</a>,
              DOI 10.17487/RFC6298, June 2011,
              &lt;<a href="https://www.rfc-editor.org/info/rfc6298">https://www.rfc-editor.org/info/rfc6298</a>&gt;.

   [<a id="ref-RFC6675">RFC6675</a>]  Blanton, E., Allman, M., Wang, L., Jarvinen, I., Kojo, M.,
              and Y. Nishida, &quot;A Conservative Loss Recovery Algorithm
              Based on Selective Acknowledgment (SACK) for TCP&quot;,
              <a href="/doc/html/rfc6675">RFC 6675</a>, DOI 10.17487/RFC6675, August 2012,
              &lt;<a href="https://www.rfc-editor.org/info/rfc6675">https://www.rfc-editor.org/info/rfc6675</a>&gt;.

   [<a id="ref-RFC7323">RFC7323</a>]  Borman, D., Braden, B., Jacobson, V., and R.
              Scheffenegger, Ed., &quot;TCP Extensions for High Performance&quot;,
              <a href="/doc/html/rfc7323">RFC 7323</a>, DOI 10.17487/RFC7323, September 2014,
              &lt;<a href="https://www.rfc-editor.org/info/rfc7323">https://www.rfc-editor.org/info/rfc7323</a>&gt;.

   [<a id="ref-RFC793">RFC793</a>]   Postel, J., &quot;Transmission Control Protocol&quot;, STD 7,
              <a href="/doc/html/rfc793">RFC 793</a>, DOI 10.17487/RFC0793, September 1981,
              &lt;<a href="https://www.rfc-editor.org/info/rfc793">https://www.rfc-editor.org/info/rfc793</a>&gt;.

   [<a id="ref-RFC8174">RFC8174</a>]  Leiba, B., &quot;Ambiguity of Uppercase vs Lowercase in <a href="/doc/html/rfc2119">RFC</a>
              <a href="/doc/html/rfc2119">2119</a> Key Words&quot;, <a href="/doc/html/bcp14">BCP 14</a>, <a href="/doc/html/rfc8174">RFC 8174</a>, DOI 10.17487/RFC8174,
              May 2017, &lt;<a href="https://www.rfc-editor.org/info/rfc8174">https://www.rfc-editor.org/info/rfc8174</a>&gt;.

<span class="h3"><a class="selflink" id="section-12.2" href="#section-12.2">12.2</a>.  Informative References</span>

   [<a id="ref-DMCG11">DMCG11</a>]   Dukkipati, N., Matthis, M., Cheng, Y., and M. Ghobadi,
              &quot;Proportional Rate Reduction for TCP&quot;, Proceedings of the
              2011 ACM SIGCOMM Conference on Internet Measurement
              Conference pp. 155-170, DOI 10.1145/2068816.2068832,
              November 2011, &lt;<a href="https://doi.org/10.1145/2068816.2068832">https://doi.org/10.1145/2068816.2068832</a>&gt;.

   [<a id="ref-FACK">FACK</a>]     Mathis, M. and J. Mahdavi, &quot;Forward acknowledgement:
              refining TCP congestion control&quot;, ACM SIGCOMM Computer
              Communication Review Volume 26, Issue 4,
              DOI 10.1145/248157.248181, August 1996,
              &lt;<a href="https://doi.org/10.1145/248157.248181">https://doi.org/10.1145/248157.248181</a>&gt;.

   [<a id="ref-POLICER16">POLICER16</a>]
              Flach, T., Papageorge, P., Terzis, A., Pedrosa, L., Cheng,
              Y., Karim, T., Katz-Bassett, E., and R. Govindan, &quot;An
              Internet-Wide Analysis of Traffic Policing&quot;, Proceedings
              of the 2016 ACM SIGCOMM Conference pp. 468-482,
              DOI 10.1145/2934872.2934873, August 2016,
              &lt;<a href="https://doi.org/10.1145/2934872.2934873">https://doi.org/10.1145/2934872.2934873</a>&gt;.

   [<a id="ref-QUIC-LR">QUIC-LR</a>]  Iyengar, J. and I. Swett, &quot;QUIC Loss Detection and
              Congestion Control&quot;, Work in Progress, Internet-Draft,
              <a href="/doc/html/draft-ietf-quic-recovery-34">draft-ietf-quic-recovery-34</a>, 14 January 2021,
              &lt;<a href="https://tools.ietf.org/html/draft-ietf-quic-recovery-34">https://tools.ietf.org/html/draft-ietf-quic-recovery-34</a>&gt;.

   [<a id="ref-RFC3042">RFC3042</a>]  Allman, M., Balakrishnan, H., and S. Floyd, &quot;Enhancing
              TCP&#x27;s Loss Recovery Using Limited Transmit&quot;, <a href="/doc/html/rfc3042">RFC 3042</a>,
              DOI 10.17487/RFC3042, January 2001,
              &lt;<a href="https://www.rfc-editor.org/info/rfc3042">https://www.rfc-editor.org/info/rfc3042</a>&gt;.

   [<a id="ref-RFC3522">RFC3522</a>]  Ludwig, R. and M. Meyer, &quot;The Eifel Detection Algorithm
              for TCP&quot;, <a href="/doc/html/rfc3522">RFC 3522</a>, DOI 10.17487/RFC3522, April 2003,
              &lt;<a href="https://www.rfc-editor.org/info/rfc3522">https://www.rfc-editor.org/info/rfc3522</a>&gt;.

   [<a id="ref-RFC4653">RFC4653</a>]  Bhandarkar, S., Reddy, A. L. N., Allman, M., and E.
              Blanton, &quot;Improving the Robustness of TCP to Non-
              Congestion Events&quot;, <a href="/doc/html/rfc4653">RFC 4653</a>, DOI 10.17487/RFC4653, August
              2006, &lt;<a href="https://www.rfc-editor.org/info/rfc4653">https://www.rfc-editor.org/info/rfc4653</a>&gt;.

   [<a id="ref-RFC5682">RFC5682</a>]  Sarolahti, P., Kojo, M., Yamamoto, K., and M. Hata,
              &quot;Forward RTO-Recovery (F-RTO): An Algorithm for Detecting
              Spurious Retransmission Timeouts with TCP&quot;, <a href="/doc/html/rfc5682">RFC 5682</a>,
              DOI 10.17487/RFC5682, September 2009,
              &lt;<a href="https://www.rfc-editor.org/info/rfc5682">https://www.rfc-editor.org/info/rfc5682</a>&gt;.

   [<a id="ref-RFC5827">RFC5827</a>]  Allman, M., Avrachenkov, K., Ayesta, U., Blanton, J., and
              P. Hurtig, &quot;Early Retransmit for TCP and Stream Control
              Transmission Protocol (SCTP)&quot;, <a href="/doc/html/rfc5827">RFC 5827</a>,
              DOI 10.17487/RFC5827, May 2010,
              &lt;<a href="https://www.rfc-editor.org/info/rfc5827">https://www.rfc-editor.org/info/rfc5827</a>&gt;.

   [<a id="ref-RFC6937">RFC6937</a>]  Mathis, M., Dukkipati, N., and Y. Cheng, &quot;Proportional
              Rate Reduction for TCP&quot;, <a href="/doc/html/rfc6937">RFC 6937</a>, DOI 10.17487/RFC6937,
              May 2013, &lt;<a href="https://www.rfc-editor.org/info/rfc6937">https://www.rfc-editor.org/info/rfc6937</a>&gt;.

   [<a id="ref-RFC7765">RFC7765</a>]  Hurtig, P., Brunstrom, A., Petlund, A., and M. Welzl, &quot;TCP
              and Stream Control Transmission Protocol (SCTP) RTO
              Restart&quot;, <a href="/doc/html/rfc7765">RFC 7765</a>, DOI 10.17487/RFC7765, February 2016,
              &lt;<a href="https://www.rfc-editor.org/info/rfc7765">https://www.rfc-editor.org/info/rfc7765</a>&gt;.

   [<a id="ref-SCWA99">SCWA99</a>]   Savage, S., Cardwell, N., Wetherall, D., and T. Anderson,
              &quot;TCP congestion control with a misbehaving receiver&quot;, ACM
              Computer Communication Review 29(5),
              DOI 10.1145/505696.505704, October 1999,
              &lt;<a href="https://doi.org/10.1145/505696.505704">https://doi.org/10.1145/505696.505704</a>&gt;.

   [<a id="ref-SPROUT">SPROUT</a>]   Winstein, K., Sivaraman, A., and H. Balakrishnan,
              &quot;Stochastic Forecasts Achieve High Throughput and Low
              Delay over Cellular Networks&quot;, 10th USENIX Symposium on
              Networked Systems Design and Implementation (NSDI &#x27;13)&quot;,
              2013.

Acknowledgments

   The authors thank Matt Mathis for his insights in FACK and Michael
   Welzl for his per-packet timer idea that inspired this work.  Eric
   Dumazet, Randy Stewart, Van Jacobson, Ian Swett, Rick Jones, Jana
   Iyengar, Hiren Panchasara, Praveen Balasubramanian, Yoshifumi
   Nishida, Bob Briscoe, Felix Weinrank, Michael Tüxen, Martin Duke,
   Ilpo Jarvinen, Theresa Enghardt, Mirja Kühlewind, Gorry Fairhurst,
   Markku Kojo, and Yi Huang contributed to this document or the
   implementations in Linux, FreeBSD, Windows, and QUIC.

Authors&#x27; Addresses

   Yuchung Cheng
   Google, Inc.

   Email: ycheng@google.com


   Neal Cardwell
   Google, Inc.

   Email: ncardwell@google.com


   Nandita Dukkipati
   Google, Inc.

   Email: nanditad@google.com


   Priyaranjan Jha
   Google, Inc.

   Email: priyarjha@google.com
</pre>
    </div>

  </div>


        
	  </div>

	

	

    </div>

      
      <script>$(".visible-nojs").removeClass("visible-nojs");</script>
      <script>$(".hidden-nojs").removeClass("hidden-nojs");</script>
      
    <script type="text/javascript"><!--
    var legend_html = "Colour legend:<br /> \
     <table> \
        <tr><td>Unknown:</td>                   <td><span class='cplate bgwhite'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Draft:</td>                     <td><span class='cplate bgred'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Informational:</td>             <td><span class='cplate bgorange'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Experimental:</td>              <td><span class='cplate bgyellow'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Best Common Practice:</td>      <td><span class='cplate bgmagenta'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Proposed Standard:</td>         <td><span class='cplate bgblue'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Draft Standard (old designation):</td> <td><span class='cplate bgcyan'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Internet Standard:</td>         <td><span class='cplate bggreen'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Historic:</td>                  <td><span class='cplate bggrey'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
        <tr><td>Obsolete:</td>                  <td><span class='cplate bgbrown'>&nbsp;&nbsp;&nbsp;&nbsp;</span></td></tr> \
    </table>";
    function showLegend() {
        var elem = document.getElementById('legend');
        elem.innerHTML = legend_html
        elem.style.visibility='visible';
    }
    function hideLegend() {
        var elem = document.getElementById('legend');
        elem.style.visibility='hidden';
        elem.innerHTML = "";
    }
    // -->
    </script>

  </body>
</html>

